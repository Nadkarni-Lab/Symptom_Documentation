{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.stats as st\n",
    "from scipy.special import ndtri\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/Symptom_Documentation/')\n",
    "\n",
    "from functions import helpers as hf \n",
    "from functions import helpers_plot as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068153b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "projectfolder = '/Users/Symptoms_Documentation/'\n",
    "datafolder = projectfolder + 'data/'\n",
    "figfolder = projectfolder + 'figures/'\n",
    "\n",
    "df_survey = pd.read_csv(datafolder + 'by_person.csv')  # survey responses\n",
    "df_demog = pd.read_csv(datafolder + 'data.csv')  # demographic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get race\n",
    "\n",
    "info_filt = ~pd.isna(df_demog['mrn'])\n",
    "\n",
    "hispanic_filt = df_demog['hispanic'] == 1\n",
    "study_ids = df_demog.loc[info_filt, 'studyid']\n",
    "study_id_hisp = df_demog.loc[info_filt & hispanic_filt, 'studyid'].to_list()\n",
    "study_id_other = df_demog.loc[info_filt & ~hispanic_filt, 'studyid'].to_list()\n",
    "\n",
    "print('Hispanic:', len(study_id_hisp), ', Non-Hispanic:', len(study_id_other))\n",
    "\n",
    "## gender\n",
    "# 0, Female | 1, Male | 2, Not reported\n",
    "\n",
    "info_filt = ~pd.isna(df_demog['mrn'])\n",
    "male_filt = df_demog['gender'] == 1\n",
    "female_filt = df_demog['gender'] == 0\n",
    "study_id_male = df_demog.loc[info_filt & male_filt, 'studyid'].to_list()\n",
    "study_id_female = df_demog.loc[info_filt & female_filt, 'studyid'].to_list()\n",
    "\n",
    "print('Male:', len(study_id_male), ', Female:', len(study_id_female))\n",
    "\n",
    "# clean survey to contain only relevant columns\n",
    "\n",
    "symptom_list = ['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']\n",
    "pt_list = symptom_list\n",
    "doc_list = [s + '_doc' for s in symptom_list]\n",
    "nurse_list = [s + '_nurse' for s in symptom_list]\n",
    "severity_list = [s + 'severity' for s in symptom_list]\n",
    "df_survey_clean = df_survey[['studyid', 'date', 'date_nurse'] + pt_list + nurse_list + doc_list + severity_list]\n",
    "\n",
    "# convert severity rating to integer from 0 to 4\n",
    "df_survey_clean[severity_list] = np.round(df_survey_clean[severity_list]/25)\n",
    "\n",
    "print('# rows:', len(df_survey_clean))\n",
    "# display(df_survey_clean[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182617d-f72f-4bf3-bc68-577056910aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condense table so that 1 survey pair = 1 row\n",
    "\n",
    "symptom_list = ['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']\n",
    "pt_list = symptom_list\n",
    "doc_list = [s + '_doc' for s in symptom_list]\n",
    "nurse_list = [s + '_nurse' for s in symptom_list]\n",
    "severity_list = [s + 'severity' for s in symptom_list]\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "for study_id in df_survey_clean['studyid'].unique():\n",
    "    id_filt = df_survey_clean['studyid'] == study_id\n",
    "    df = df_survey_clean.loc[id_filt, :]\n",
    "\n",
    "    pt_filt = df['date'].notna()\n",
    "    nurse_filt = df['date_nurse'].notna()\n",
    "    doc_filt = df['date'].isna() & df['date_nurse'].isna()\n",
    "\n",
    "    df_pt = df.loc[pt_filt, ['studyid', 'date'] + pt_list + severity_list].reset_index(drop=True)\n",
    "    df_nurse = df.loc[nurse_filt, nurse_list].reset_index(drop=True)\n",
    "    df_doc = df.loc[doc_filt, doc_list].reset_index(drop=True)\n",
    "    df_doc['date'] = df_pt['date'].iloc[-1]\n",
    "\n",
    "    df_combined = pd.concat([df_pt, df_nurse], axis=1)\n",
    "    df_combined = df_combined.merge(df_doc, on='date', how='left')\n",
    "    df_combined.insert(1, 'week', [i//3 + 1 for i in range(0, len(df_combined))])\n",
    "\n",
    "    df_final = pd.concat([df_final, df_combined], ignore_index=True)\n",
    "\n",
    "display(df_final[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c19df6-5396-492c-9074-805264da9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condense table so that 1 row = 1 week\n",
    "\n",
    "symptom_list = ['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']\n",
    "pt_list = symptom_list\n",
    "doc_list = [s + '_doc' for s in symptom_list]\n",
    "nurse_list = [s + '_nurse' for s in symptom_list]\n",
    "severity_list = [s + 'severity' for s in symptom_list]\n",
    "\n",
    "df_byweek = pd.DataFrame()\n",
    "\n",
    "for study_id in df_final['studyid'].unique():\n",
    "    id_filt = df_final['studyid'] == study_id\n",
    "    for week in [1,2,3,4]:\n",
    "        week_filt = df_final['week'] == week\n",
    "        df_pt_week = df_final.loc[id_filt & week_filt, :]\n",
    "        \n",
    "        pt_sym = df_pt_week.loc[:, pt_list].max()\n",
    "        nurse_sym = df_pt_week.loc[:, nurse_list].max()\n",
    "        doc_sym = df_pt_week.loc[:, doc_list].max()\n",
    "        sym_sev = df_pt_week.loc[:, severity_list].max()\n",
    "\n",
    "        combined = pd.concat([pt_sym, nurse_sym, doc_sym, sym_sev])\n",
    "\n",
    "        df = pd.DataFrame([combined.tolist()], columns=combined.index)\n",
    "        df.insert(0, 'week', week)\n",
    "        df.insert(0, 'study_id', study_id)\n",
    "\n",
    "        df_byweek = pd.concat([df_byweek, df], ignore_index=True)\n",
    "\n",
    "    # df_final = pd.concat([df_final, df_combined], ignore_index=True)\n",
    "\n",
    "display(df_byweek[0:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Kappa scores between patient + nurse and patient + physician\n",
    "\n",
    "symptom_list = ['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']\n",
    "doc_list = [s + '_doc' for s in symptom_list]\n",
    "nurse_list = [s + '_nurse' for s in symptom_list]\n",
    "\n",
    "kappa_nurse = {}\n",
    "kappa_doc = {}\n",
    "\n",
    "for sym in symptom_list:\n",
    "    print(sym)\n",
    "    nurse_kappa_week = {}\n",
    "    doc_kappa_week = {}\n",
    "    for week in range(1,5):\n",
    "        print(week)\n",
    "        df_byweek_subset = df_byweek[df_byweek[\"week\"] == week]\n",
    "    \n",
    "        pt_scores = df_byweek_subset[sym]\n",
    "        print(\"Number of patient scores as NaN:\", sum(np.isnan(pt_scores)))\n",
    "        nurse_scores = df_byweek_subset[sym + \"_nurse\"]\n",
    "        print(\"Number of nurse scores as NaN:\", sum(np.isnan(nurse_scores)))\n",
    "        nurse_kappa_week[week] = round(cohen_kappa_score(pt_scores, nurse_scores), 2)\n",
    "\n",
    "        if week == 4:\n",
    "            doc_scores = df_byweek_subset[sym + \"_doc\"]\n",
    "            print(\"Number of doctor scores as Nan\", sum(np.isnan(doc_scores)))\n",
    "            doc_kappa_week[week] = round(cohen_kappa_score(pt_scores, doc_scores), 2)\n",
    "        else:\n",
    "            doc_kappa_week[week] = None\n",
    "    kappa_nurse[sym] = nurse_kappa_week\n",
    "    kappa_doc[sym] = doc_kappa_week\n",
    "\n",
    "print(kappa_nurse)\n",
    "print(kappa_doc)\n",
    "\n",
    "kappa_nurse_df = pd.DataFrame(kappa_nurse)\n",
    "kappa_doc_df = pd.DataFrame(kappa_doc)\n",
    "\n",
    "display(kappa_nurse_df)\n",
    "display(kappa_doc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261a92a-c54c-41f8-ba76-e4ad95c31ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa_bysurvey(symp_pt, symp_clin, all_symptoms=['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']):\n",
    "    \n",
    "    # total number of symptoms that both raters said were present\n",
    "    A = len(np.intersect1d(symp_pt, symp_clin))\n",
    "    \n",
    "    # total number of symptoms rater 2 said was absent but rater 1 said was present\n",
    "    B = len(np.intersect1d(np.setdiff1d(all_symptoms, symp_clin), symp_pt))\n",
    "    \n",
    "    # total number of symptoms rater 1 said was absent but rater 2 said was present\n",
    "    C = len(np.intersect1d(np.setdiff1d(all_symptoms, symp_pt), symp_clin))\n",
    "    \n",
    "    # total number of symptoms both raters said were absent\n",
    "    D = len(np.intersect1d(np.setdiff1d(all_symptoms, symp_pt), np.setdiff1d(all_symptoms, symp_clin)))\n",
    "\n",
    "    # print(A, B, C, D)\n",
    "\n",
    "    # probability of agreement\n",
    "    p_a = (A+D) / (A+B+C+D)\n",
    "    p_correct = ((A+B)/(A+B+C+D)) * ((A+C)/(A+B+C+D))\n",
    "    p_incorrect = ((C+D)/(A+B+C+D)) * ((B+D)/(A+B+C+D))\n",
    "    p_e = p_correct + p_incorrect\n",
    "\n",
    "    try:\n",
    "        kappa = (p_a - p_e) / (1 - p_e)\n",
    "    except ZeroDivisionError as e:\n",
    "        kappa = np.nan\n",
    "        # print(p_a - p_e, 1 - p_e)\n",
    "        # print('division by zero error')\n",
    "        \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93dc19-5705-4fc5-b9cb-51d980928618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# kappa between patient + nurse, patient + doctor per week\n",
    "\n",
    "symptom_list = ['cramp', 'fatigue', 'musclesore', 'dryskin', 'itching']\n",
    "pt_list = symptom_list\n",
    "doc_list = [s + '_doc' for s in symptom_list]\n",
    "nurse_list = [s + '_nurse' for s in symptom_list]\n",
    "\n",
    "kappa_nurse_list = []\n",
    "kappa_doc_list = []\n",
    "\n",
    "for row in df_byweek.itertuples():\n",
    "    pt_symptoms = []\n",
    "    nurse_symptoms = []\n",
    "    doc_symptoms = []\n",
    "    for sym in symptom_list:\n",
    "        if getattr(row, sym) == 1:\n",
    "            pt_symptoms.append(sym)\n",
    "        if getattr(row, sym + '_nurse') == 1:\n",
    "            nurse_symptoms.append(sym)\n",
    "        if getattr(row, sym + '_doc') == 1:\n",
    "            doc_symptoms.append(sym)\n",
    "\n",
    "    if len(doc_symptoms) > 0:\n",
    "        kappa_doc = get_kappa_bysurvey(pt_symptoms, doc_symptoms, symptom_list)\n",
    "    else:\n",
    "        kappa_doc = np.nan\n",
    "    \n",
    "    kappa_nurse = get_kappa_bysurvey(pt_symptoms, nurse_symptoms, symptom_list)\n",
    "    kappa_nurse_list.append(kappa_nurse)\n",
    "    kappa_doc_list.append(kappa_doc)\n",
    "            \n",
    "df_byweek['kappa_nurse'] = kappa_nurse_list\n",
    "df_byweek['kappa_doc'] = kappa_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e07ffa-97d9-45f1-9014-171c38d48d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the distribution of kappa and the average kappa across all symptoms\n",
    "kappa_list = []\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "for i in range(1, 5):\n",
    "    week_filt = df_byweek['week'] == i\n",
    "    nurse_kappas = df_byweek.loc[week_filt, 'kappa_nurse']\n",
    "    doc_kappas = df_byweek.loc[week_filt, 'kappa_doc']\n",
    "    plt.subplot(1,4,i)\n",
    "    plt.hist(nurse_kappas, range=[-1,1], bins=20)\n",
    "    plt.ylim([0, 60])\n",
    "    plt.title('Week ' + str(i))\n",
    "\n",
    "    kappa_list.append({'Mean (nurse)': np.nanmean(nurse_kappas), \\\n",
    "                       'Std (nurse)': np.std(nurse_kappas), \\\n",
    "                       'Mean (physician)': np.nanmean(doc_kappas), \\\n",
    "                       'Std (physician)': np.std(doc_kappas)})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_kappa = pd.DataFrame(kappa_list)\n",
    "display(df_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd47f4d-b2f7-4b1c-a7ef-f34c60d1dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa.to_csv(projectfolder + 'results/kappa_byweek.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of symptoms as reported by patient, doctor, nurse, and NLP\n",
    "\n",
    "uniq_sids = df_survey_clean['studyid'].unique()\n",
    "symptom_dict = {}   # key = reporter+symptom, value=list of studyids\n",
    "severity_dict = {}  # key1 = symptom, key2=severity, value = list of studyids w/ that symptom and severity\n",
    "\n",
    "# create dictionary structure\n",
    "for col in pt_list:\n",
    "    severity_dict[col] = {}\n",
    "    for i in range(0, 5):\n",
    "        severity_dict[col][i] = []\n",
    "\n",
    "for sid in uniq_sids:\n",
    "    sid_filt = df_survey_clean['studyid'] == sid\n",
    "    for col in pt_list:\n",
    "        if np.sum(df_survey_clean.loc[sid_filt, col]) > 0:  # patient has reported symptom\n",
    "            severity_label = col.split('_')[0] + 'severity'  \n",
    "            severity = np.max(df_survey_clean.loc[sid_filt, severity_label]) # get patient-reported severity\n",
    "            if not pd.isna(severity):\n",
    "                severity_dict[col][severity].append(sid)\n",
    "            else:\n",
    "                severity_dict[col][0].append(sid)\n",
    "            \n",
    "for sid in uniq_sids:\n",
    "    sid_filt = df_survey_clean['studyid'] == sid\n",
    "    for col in nurse_list + doc_list:\n",
    "        if np.sum(df_survey_clean.loc[sid_filt, col]) > 0:\n",
    "            if col not in symptom_dict:\n",
    "                symptom_dict[col] = []\n",
    "            symptom_dict[col].append(sid)\n",
    "            \n",
    "# NLP results copied and pasted from NLP code\n",
    "\n",
    "symptom_dict['cramp_nlp'] = [1, 3, 9, 11, 16, 18, 19, 20, 34, 36, 38, 50, 51, 54, 56, 57, 60, 65, 69, 70, 73, 76, 81, 82, 84, 100]\n",
    "symptom_dict['fatigue_nlp'] = [8, 19, 33, 39, 42, 49, 61, 62, 75, 78, 79, 81, 89, 93]\n",
    "symptom_dict['itching_nlp'] = [2, 3, 6, 9, 10, 11, 16, 31, 37, 38, 47, 54, 60, 62, 66, 75, 77, 83, 97, 100]\n",
    "symptom_dict['musclesore_nlp'] = [1, 42, 66, 73, 76, 86, 88, 94, 95]\n",
    "symptom_dict['dryskin_nlp'] = []\n",
    "\n",
    "symptom_label_map = {'cramp': 'Cramp', 'fatigue': 'Fatigue', 'musclesore': 'Muscle Soreness', \\\n",
    "                     'itching': 'Itching', 'dryskin': 'Dry Skin'}\n",
    "rater_label_map = {'nurse': 'Nurse', 'doc': 'Physician', 'nlp': 'NLP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf93d9-7b0d-4397-aba6-ad05965dbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE 2 - Bar Plot of Number of Reported Patients by Patient, Nurse, Physician, Nurse + Physician, and NLP\n",
    "\n",
    "plt.figure(figsize=[9, 4])\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.14\n",
    "\n",
    "# only above certain severity\n",
    "sev_cutoff = 0\n",
    "keys_all = list(symptom_dict.keys())\n",
    "\n",
    "counts_byrater = {'actual': [], 'nlp': [], 'doc': [], 'nurse': [], 'doc+nurse': []}\n",
    "rater_order = ['actual', 'nurse', 'doc', 'doc+nurse', 'nlp']\n",
    "rater_label_map = {'actual': 'Patient Survey', 'nurse': 'Nurse Survey', \\\n",
    "                   'doc': 'Physician Survey', 'nlp': 'NLP of EHR', 'doc+nurse': 'Nurse+Physician Surveys'}\n",
    "color_map = {'actual': '#292787', 'nurse': '#68686b', 'doc': '#a35149', 'nlp': '#d1c886', 'doc+nurse': '#AFE1AF'}\n",
    "symptom_label_map = {'cramp': 'Cramp', 'fatigue': 'Fatigue', 'musclesore': 'Muscle Soreness', \\\n",
    "                     'itching': 'Itching', 'dryskin': 'Dry Skin'}\n",
    "symptom_order = ['fatigue', 'cramp', 'dryskin', 'musclesore', 'itching']\n",
    "\n",
    "for i, sym in enumerate(symptom_order):\n",
    "    sym_keys = [k for k in keys_all if sym in k]\n",
    "    species = tuple(['pt']+[k.replace(sym+'_', '') for k in sym_keys])\n",
    "    \n",
    "    actual_sids = [severity_dict[sym][s] for s in severity_dict[sym] if s>=sev_cutoff]\n",
    "    actual_sids = [*set(list(itertools.chain(*actual_sids)))]\n",
    "    \n",
    "    counts_byrater['actual'].append(len(actual_sids))\n",
    "    \n",
    "    for k in sym_keys:\n",
    "        rater = k.split('_')[1]\n",
    "        sids_byrater = symptom_dict[k]\n",
    "        counts_byrater[rater].append(len(sids_byrater))\n",
    "\n",
    "    sids_bynurse = symptom_dict[sym + '_nurse']\n",
    "    sids_bydoc = symptom_dict[sym + '_doc']\n",
    "    sids_both = np.unique(sids_bynurse + sids_bydoc)\n",
    "    counts_byrater['doc+nurse'].append(len(sids_both))\n",
    "\n",
    "for i, rater in enumerate(rater_order):\n",
    "    barheights = counts_byrater[rater]\n",
    "    if i==0:\n",
    "        barposition = np.arange(len(barheights))\n",
    "    else:\n",
    "        barposition = [x+barWidth for x in prevbar]\n",
    "    prevbar = barposition\n",
    "    plt.bar(barposition, barheights, width=barWidth, label=rater_label_map[rater], \\\n",
    "            color=color_map[rater], edgecolor = 'black')\n",
    "\n",
    "# # Adding Xticks\n",
    "plt.xlabel('Symptom', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('# Reported Patients', fontweight ='bold', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(symptom_order))], \\\n",
    "           [symptom_label_map[sym] for sym in symptom_order])\n",
    " \n",
    "# plt.box(False)\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(figfolder + 'fig2_updated_v2.png', dpi=200,  bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc585c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe that contains unique study IDs and symptom presence based on severity thresholds and rater source\n",
    "# Contains demographic information\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "df_sym = pd.DataFrame({'Study ID': all_ids})\n",
    "\n",
    "sev_cutoff = 0\n",
    "raters = ['doc', 'nurse', 'nlp']\n",
    "for sym in severity_dict.keys():\n",
    "    actual_ids = [severity_dict[sym][s] for s in severity_dict[sym] if s>=sev_cutoff]\n",
    "    actual_ids = [*set(list(itertools.chain(*actual_ids)))]\n",
    "    df_sym[sym + '_actual'] = df_sym['Study ID'].isin(actual_ids).to_list()\n",
    "    \n",
    "    for r in raters:\n",
    "        rater_ids = symptom_dict[sym + '_' + r]\n",
    "        df_sym[sym + '_' + r] = df_sym['Study ID'].isin(rater_ids).to_list()\n",
    "\n",
    "df_sym['gender'] = 'female'\n",
    "df_sym.loc[df_sym['Study ID'].isin(study_id_male), 'gender'] = 'male'\n",
    "df_sym['race'] = 'hispanic'\n",
    "df_sym.loc[df_sym['Study ID'].isin(study_id_other), 'race'] = 'nonhispanic'\n",
    "\n",
    "highsev_ids = []\n",
    "sev_min = 3\n",
    "for sym in severity_dict:\n",
    "    for sev in range(sev_min, 5):\n",
    "        highsev_ids.extend(severity_dict[sym][sev])\n",
    "    \n",
    "highsev_ids = np.unique(highsev_ids)\n",
    "df_sym['severity'] = 'low'\n",
    "df_sym.loc[df_sym['Study ID'].isin(highsev_ids), 'severity'] = 'high'\n",
    "\n",
    "display(df_sym.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve unique IDs of patients with high severity or low severity symptoms\n",
    "highsev_ids = []\n",
    "sev_min = 3\n",
    "for sym in severity_dict:\n",
    "    for sev in range(sev_min, 5):\n",
    "        highsev_ids.extend(severity_dict[sym][sev])\n",
    "    \n",
    "highsev_ids = np.unique(highsev_ids)\n",
    "lowsev_ids = np.setdiff1d(uniq_sids, highsev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot percentage of patients reporting symptom\n",
    "symptoms = ['fatigue', 'cramp', 'dryskin', 'musclesore', 'itching']\n",
    "counts = []\n",
    "for sym in symptoms:\n",
    "    sym_count = 0\n",
    "    for sev in severity_dict[sym]:\n",
    "        if sev > 0:\n",
    "            sym_count += len(severity_dict[sym][sev])\n",
    "    counts.append(100*sym_count / len(uniq_sids))\n",
    "    \n",
    "plt.figure(figsize=(3,2.8))\n",
    "plt.bar([symptom_label_map[sym] for sym in symptoms], counts, width=0.8)\n",
    "plt.ylabel('% of patients reporting symptom')\n",
    "# plt.xlabel('Symptom')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.autoscale()\n",
    "plt.savefig(figfolder + 'fig1.pdf', format='pdf', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(symptom_dict.keys())\n",
    "print(severity_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plots sensitivity, specificity, PPV, and NPV for patients based on rater source and symptom\n",
    "all_ids = df_survey_clean['studyid'].unique()  # all patients\n",
    "actual_ids = hf.get_ids_ACTUAL(severity_dict)  # all patients with ANY symptom reported\n",
    "\n",
    "fig1 = hp.plot_combined(symptom_dict, all_ids, actual_ids, figfolder+'fig3a.png')\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "actual_ids_low = hf.get_ids_ACTUAL(severity_dict, 1, 2)\n",
    "actual_ids_hi = hf.get_ids_ACTUAL(severity_dict, 3, 4)\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "\n",
    "fig2 = hp.plot_bysymptom(symptom_dict, all_ids, actual_id_dict, figfolder + 'fig3b.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ea060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plots sensitivity, specificity, PPV, and NPV for patients based on rater source and symptom\n",
    "# Severity low vs high\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "actual_ids_low = hf.get_ids_ACTUAL(severity_dict, 1, 2)\n",
    "actual_ids_hi = hf.get_ids_ACTUAL(severity_dict, 3, 4)\n",
    "\n",
    "actual_id_dict = {'Severity < 3': actual_ids_low, 'Severity ≥ 3': actual_ids_hi}\n",
    "color_dict = {'Severity < 3': '#0000a7', 'Severity ≥ 3': '#c1272d'}\n",
    "\n",
    "hp.plot_bygroup(symptom_dict, all_ids, actual_id_dict, color_dict, figfolder + 'fig4a_updated.png')\n",
    "\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "\n",
    "cohort_dict = {'Severity<3': highsev_ids, 'Severity≥3': lowsev_ids}\n",
    "color_dict = {'Severity<3': '#0000a7', 'Severity≥3': '#c1272d'}\n",
    "\n",
    "hp.plot_bysymptom_bygroup(symptom_dict, actual_id_dict, cohort_dict, color_dict, \\\n",
    "                          figfolder+'fig_supp3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb18d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plots sensitivity, specificity, PPV, and NPV for patients based on rater source and symptom\n",
    "# non-hispanic vs hispanic\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "\n",
    "actual_id_dict = {'Non-Hispanic': study_id_other, 'Hispanic': study_id_hisp}\n",
    "color_dict = {'Non-Hispanic': '#0000a7', 'Hispanic': '#c1272d'}\n",
    "\n",
    "hp.plot_bygroup(symptom_dict, all_ids, actual_id_dict, color_dict, figfolder + 'fig4b_updated.png')\n",
    "\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "\n",
    "cohort_dict = {'Non-Hispanic': study_id_other, 'Hispanic': study_id_hisp}\n",
    "color_dict = {'Non-Hispanic': '#0000a7', 'Hispanic': '#c1272d'}\n",
    "\n",
    "hp.plot_bysymptom_bygroup(symptom_dict, actual_id_dict, cohort_dict, color_dict, \\\n",
    "                          figfolder+'fig_supp2_corrected.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plots sensitivity, specificity, PPV, and NPV for patients based on rater source and symptom\n",
    "# male vs female\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "\n",
    "actual_id_dict = {'Male': study_id_male, 'Female': study_id_female}\n",
    "color_dict = {'Male': '#0000a7', 'Female': '#c1272d'}\n",
    "\n",
    "hp.plot_bygroup(symptom_dict, all_ids, actual_id_dict, color_dict, figfolder + 'fig4c.png')\n",
    "\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "\n",
    "cohort_dict = {'Male': study_id_male, 'Female': study_id_female}\n",
    "color_dict = {'Male': '#0000a7', 'Female': '#c1272d'}\n",
    "\n",
    "figfolder = projectfolder + 'figures/'\n",
    "hp.plot_bysymptom_bygroup(symptom_dict, actual_id_dict, cohort_dict, color_dict, \\\n",
    "                          filename=figfolder+'fig_supp1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af33e8-f713-445e-b590-6c4725848dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low vs high frequency of reported symptoms\n",
    "# high frequency = pt reported symptoms >= 50% of the time; else low\n",
    "\n",
    "freq_dict = {'highfreq': {}, 'lowfreq': {}}\n",
    "for studyid in df_final['studyid'].unique():\n",
    "    id_filt = df_final['studyid'] == studyid\n",
    "    for sym in symptom_list:\n",
    "        sym_count = df_final.loc[id_filt, sym].sum()\n",
    "        if (sym_count / np.sum(id_filt)) >= 0.5:\n",
    "            if sym not in freq_dict['highfreq']:\n",
    "                freq_dict['highfreq'][sym] = []\n",
    "            freq_dict['highfreq'][sym].append(studyid)\n",
    "        else:\n",
    "            if sym not in freq_dict['lowfreq']:\n",
    "                freq_dict['lowfreq'][sym] = []\n",
    "            freq_dict['lowfreq'][sym].append(studyid)\n",
    "# high frequency vs low frequency reporting\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "\n",
    "highfreq_ids = sum([freq_dict['highfreq'][sym] for sym in freq_dict['highfreq']], [])\n",
    "lowfreq_ids = sum([freq_dict['lowfreq'][sym] for sym in freq_dict['lowfreq']], [])\n",
    "\n",
    "actual_id_dict = {'High Frequency': highfreq_ids, 'Low Frequency': lowfreq_ids}\n",
    "color_dict = {'High Frequency': '#0000a7', 'Low Frequency': '#c1272d'}\n",
    "\n",
    "hp.plot_bygroup(symptom_dict, all_ids, actual_id_dict, color_dict, figfolder + 'fig3c_updated.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physician survey,  nurse survey, NLP performance metrics (overall)\n",
    "# sensitivity, specificity, PPV, NPV\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "\n",
    "hp.plot_bysymptom(symptom_dict, all_ids, actual_id_dict, figfolder + 'fig3b.png')\n",
    "\n",
    "for rater in ['nurse', 'doc', 'nlp']:\n",
    "    print('\\n',rater)\n",
    "    for sym in actual_id_dict:\n",
    "        print(sym)\n",
    "        pos_ids = actual_id_dict[sym]\n",
    "        pred_pos_ids = symptom_dict[sym + '_' + rater]\n",
    "\n",
    "        conf_mat = hf.get_confusion_matrix(pos_ids, pred_pos_ids, all_ids)\n",
    "        print(conf_mat)\n",
    "        for label in conf_mat:\n",
    "            print(label, conf_mat[label] / 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f46a3e-5eb1-4250-a7bc-cadab61bd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot by symptom, grouped by raters and reported frequency\n",
    "# similar to hp.plot_bysymptom_group\n",
    "    \n",
    "symptom_label_map = {'cramp': 'Cramp', 'fatigue': 'Fatigue', 'musclesore': 'Muscle Soreness', \\\n",
    "                 'itching': 'Itching', 'dryskin': 'Dry Skin'}\n",
    "rater_label_map = {'nurse': 'Nurse', 'doc': 'Physician', 'nlp': 'NLP'}\n",
    "symptom_order = ['fatigue', 'cramp', 'dryskin', 'musclesore', 'itching'][::-1]\n",
    "cohort_label_map = {'highfreq': 'High Frequency', 'lowfreq': 'Low Frequency'}\n",
    "color_dict = {'highfreq': '#0000a7', 'lowfreq': '#c1272d'}\n",
    "\n",
    "plt.figure(figsize=[8, 6])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0)\n",
    "cols = 4\n",
    "rows = 1\n",
    "raters = ['nlp', 'doc', 'nurse']  # Set specific rater order here\n",
    "markers = ['o', 's', 'v']\n",
    "marker_dict = dict(zip(raters, markers))\n",
    "    \n",
    "for c, cohort in enumerate(freq_dict):\n",
    "    for i,rater in enumerate(raters):\n",
    "        id_dict = hf.get_id_dict_byrater(symptom_dict, rater)\n",
    "\n",
    "        # get stats by symptom\n",
    "        count = 0\n",
    "        for j,sym in enumerate(symptom_order):\n",
    "            actual_ids = freq_dict[cohort][sym]\n",
    "            ids_byrater = id_dict[sym]\n",
    "            conf_mat = hf.get_confusion_matrix(actual_ids, ids_byrater, df_final['studyid'].unique())\n",
    "            \n",
    "            sens = hf.sensitivity(conf_mat)\n",
    "            spec = hf.specificity(conf_mat)\n",
    "            ppv = hf.PPV(conf_mat)\n",
    "            npv = hf.NPV(conf_mat)\n",
    "            sens_ci, spec_ci, ppv_ci, npv_ci = hf.confidence_interval(conf_mat, alpha=0.95)\n",
    "\n",
    "            y_offset = -c*0.08\n",
    "            y = j+(i*0.2)-0.2 + y_offset\n",
    "\n",
    "            marker = marker_dict[rater]\n",
    "\n",
    "            plt.subplot(rows,cols,1)\n",
    "            plt.plot(sens_ci, (y,y), color=color_dict[cohort])\n",
    "            plt.plot(sens, y, marker, color='black')\n",
    "            plt.title('Sensitivity')\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.yticks([r for r in range(len(symptom_order))], \\\n",
    "                       [symptom_label_map[s] for s in symptom_order])\n",
    "\n",
    "            plt.subplot(rows,cols,2)\n",
    "            plt.plot(spec_ci, (y,y), color=color_dict[cohort])\n",
    "            plt.plot(spec, y, marker, color='black')\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.title('Specificity')\n",
    "            plt.tick_params(left = False)\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.subplot(rows,cols,3)\n",
    "            plt.plot(ppv_ci, (y,y), color=color_dict[cohort])\n",
    "            plt.plot(ppv, y, marker, color='black')\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.title('PPV')\n",
    "            plt.tick_params(left = False)\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.subplot(rows,cols,4)\n",
    "            if j==0:\n",
    "                plt.plot(npv_ci, (y,y), color=color_dict[cohort], label=cohort_label_map[cohort])\n",
    "                plt.plot(npv, y, marker, color='black', label=rater_label_map[rater])\n",
    "            else:\n",
    "                plt.plot(npv_ci, (y,y), color=color_dict[cohort])\n",
    "                plt.plot(npv, y, marker, color='black')\n",
    "            plt.xlim([-0.05, 1.05])\n",
    "            plt.title('NPV')\n",
    "            plt.tick_params(left = False)\n",
    "            plt.yticks([])\n",
    "\n",
    "custom_legend_handles = [\n",
    "    Line2D([0], [0], color=color_dict[cohort], marker=marker_dict[rater], markersize=6, \n",
    "            markerfacecolor='black', markeredgecolor='black', linestyle='-', \n",
    "            label=f\"{rater_label_map[rater]} {cohort_label_map[cohort]}\")\n",
    "    for cohort in reversed(cohort_dict)\n",
    "    for rater in raters \n",
    "]\n",
    "\n",
    "custom_legend_handles = custom_legend_handles[::-1]\n",
    "\n",
    "# Set the legend with custom handles\n",
    "plt.legend(handles=custom_legend_handles, loc=\"upper right\", bbox_to_anchor=(2.8, 1.0))\n",
    "plt.savefig(figfolder+'fig_supp4_symfreq_updated.png', dpi=200,  bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d35e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappa between patient + nurse, patient + doctor, patient + NLP, and patient + nurse and physician\n",
    "\n",
    "rater_label_map = {'nurse': 'Nurse', 'doc': 'Physician', 'nlp': 'NLP', 'nurse+doc': 'Nurse + Physician'}\n",
    "\n",
    "all_ids = df_survey_clean['studyid'].unique()\n",
    "actual_id_dict = hf.get_id_dict_ACTUAL(severity_dict)\n",
    "# print(actual_id_dict)\n",
    "\n",
    "raters = ['nurse', 'doc', 'nurse+doc', 'nlp']\n",
    "symptom_order = ['fatigue', 'cramp', 'dryskin', 'musclesore', 'itching']\n",
    "kappa_list = []\n",
    "for i,rater in enumerate(raters):\n",
    "    if rater == 'nurse+doc':\n",
    "        id_dict_nurse = hf.get_id_dict_byrater(symptom_dict, 'nurse')\n",
    "        id_dict_doc = hf.get_id_dict_byrater(symptom_dict, 'doc')\n",
    "        id_dict = {}\n",
    "        for sym in id_dict_nurse:\n",
    "            id_dict[sym] = np.unique(id_dict_nurse[sym], id_dict_doc[sym])\n",
    "    else:\n",
    "        id_dict = hf.get_id_dict_byrater(symptom_dict, rater)\n",
    "        \n",
    "    kappa_dict = {}\n",
    "    for sym in symptom_order:\n",
    "        actual_ids = actual_id_dict[sym]\n",
    "        rater_ids = id_dict[sym]\n",
    "        kappa = hf.get_kappa(actual_ids, rater_ids, all_ids)\n",
    "        kappa_dict[symptom_label_map[sym]] = kappa\n",
    "    kappa_list.append(kappa_dict)\n",
    "    \n",
    "df_kappa = pd.DataFrame(kappa_list, index=[rater_label_map[r] for r in raters])\n",
    "display(np.round(df_kappa, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9955ff9-d1f9-4236-9eb1-c1bfc6f25430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kappa.round(2).to_csv(projectfolder + 'results/kappa_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23f9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
